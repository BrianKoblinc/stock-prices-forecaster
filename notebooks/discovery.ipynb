{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk9b_t2iMOJu"
      },
      "source": [
        "# Discovery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B72yRKATQ161"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Optional\n",
        "from datetime import datetime, timedelta\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "class Extract():\n",
        "    def __init__(self, ticker_list, years_bf: Optional[int] = 0, months_bf: Optional[int] = 0, days_bf: Optional[int] = 0):\n",
        "        self.ticker_list = ticker_list\n",
        "        self.end = datetime.now()\n",
        "        self.start = datetime(self.end.year - years_bf, self.end.month - months_bf, self.end.day - days_bf)\n",
        "        self.load_path = 'data/'\n",
        "\n",
        "    def _read(self):\n",
        "        self.data = {}\n",
        "        files = os.listdir(self.load_path)\n",
        "        self.stocks_data = [i[:-26] for i in files]\n",
        "\n",
        "        for i in list(set(self.stocks_data) & set(self.ticker_list)):\n",
        "            date1 = files[self.stocks_data.index(i)][-14:-4]\n",
        "            start_date_file = datetime(int(date1[:4]), int(date1[5:7]), int(date1[8:10]))\n",
        "            date2 = files[self.stocks_data.index(i)][-25:-15]\n",
        "            end_date_file = datetime(int(date2[:4]), int(date2[5:7]), int(date2[8:10]))\n",
        "\n",
        "            start_date_inter = max(start_date_file, self.start)\n",
        "            end_date_inter = min(end_date_file, self.end)\n",
        "\n",
        "            if start_date_inter <= end_date_inter:\n",
        "                if self.start > start_date_file and self.end > end_date_inter:\n",
        "                    serie = pd.concat([pd.read_csv(os.path.join(self.load_path, files[self.stocks_data.index(i)])).set_index('Date')['Adj Close'],\n",
        "                                       yf.download(i, end_date_inter + timedelta(days=1), self.end)['Adj Close']])\n",
        "                    serie.index = pd.to_datetime(serie.index)\n",
        "                    self.data[i] = serie.loc[self.start:self.end]\n",
        "                    self.ticker_list.remove(i)\n",
        "\n",
        "        for file in [i for i in files if '.ipynb_checkpoints' not in i]:\n",
        "            os.remove(os.path.join(self.load_path, file))\n",
        "\n",
        "    def _load(self):\n",
        "        for stock in self.data.keys():\n",
        "            self.data[stock].to_csv(os.path.join(self.load_path, f\"{stock}_{self.data[stock].index.max().date()}_{self.data[stock].index.min().date()}.csv\"))\n",
        "\n",
        "    def run(self):\n",
        "        self._read()\n",
        "        for stock in self.ticker_list:\n",
        "            self.data[stock] = yf.download(stock, self.start, self.end)['Adj Close']\n",
        "        self._load()\n",
        "        return self.data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "axThr4BTQ9ty"
      },
      "outputs": [],
      "source": [
        "tech_list = ['AAPL', 'GOOG', 'MSFT', 'AMZN']\n",
        "\n",
        "extract = Extract(tech_list, years_bf=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmt3aBbfRE2B",
        "outputId": "39ce3daa-9f26-423c-9440-4efba62ad774"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "stocks_hist = extract.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_flzRSklSTiT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class Transform():\n",
        "  def __init__(self, data, test_size, X_days):\n",
        "    self.data = data\n",
        "    self.test_size = test_size\n",
        "    self.X_days = X_days\n",
        "\n",
        "  def _split_train_test(self):\n",
        "    self.train={}\n",
        "    self.test={}\n",
        "\n",
        "    for ticker in self.data.keys():\n",
        "      dataset = self.data[ticker].values\n",
        "      training_data_len = int(np.ceil( len(dataset) * (1-self.test_size)))\n",
        "      self.train[ticker] = dataset[:int(training_data_len)]\n",
        "      self.test[ticker] = dataset[int(training_data_len):]\n",
        "\n",
        "  def _scaler(self):\n",
        "    self.scaler={}\n",
        "\n",
        "    for ticker in self.data.keys():\n",
        "      self.scaler[ticker] = MinMaxScaler(feature_range=(0,1))\n",
        "      self.train[ticker] = self.scaler[ticker].fit_transform(self.train[ticker].reshape(-1, 1))\n",
        "      self.test[ticker] = self.scaler[ticker].transform(self.test[ticker].reshape(-1, 1))\n",
        "\n",
        "  def _split_X_y(self):\n",
        "\n",
        "    self.X_train={}\n",
        "    self.y_train={}\n",
        "    self.X_test={}\n",
        "    self.y_test={}\n",
        "\n",
        "    for ticker in self.data.keys():\n",
        "      self.X_train[ticker]=[]\n",
        "      self.y_train[ticker]=[]\n",
        "\n",
        "      for i in range(self.X_days, len(list(self.train.values())[0])):\n",
        "\n",
        "        self.X_train[ticker].append(self.train[ticker][i-self.X_days:i, 0])\n",
        "        self.y_train[ticker].append(self.train[ticker][i, 0])\n",
        "\n",
        "      self.X_train[ticker], self.y_train[ticker] = np.array(self.X_train[ticker]), np.array(self.y_train[ticker])\n",
        "      self.X_train[ticker] = np.reshape(self.X_train[ticker], (self.X_train[ticker].shape[0], self.X_train[ticker].shape[1], 1))\n",
        "\n",
        "      self.X_test[ticker]=[]\n",
        "      self.y_test[ticker]=[]\n",
        "\n",
        "      for i in range(self.X_days, len(list(self.test.values())[0])):\n",
        "\n",
        "        self.X_test[ticker].append(self.test[ticker][i-self.X_days:i, 0])\n",
        "        self.y_test[ticker].append(self.test[ticker][i, 0])\n",
        "\n",
        "      self.X_test[ticker], self.y_test[ticker] = np.array(self.X_test[ticker]), np.array(self.y_test[ticker])\n",
        "      self.X_test[ticker] = np.reshape(self.X_test[ticker], (self.X_test[ticker].shape[0], self.X_test[ticker].shape[1], 1))\n",
        "\n",
        "  def run(self):\n",
        "    self._split_train_test()\n",
        "    self._scaler()\n",
        "    self._split_X_y()\n",
        "\n",
        "    return self.X_train, self.y_train, self.X_test, self.y_test, self.scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O-h9g-YrV0Up"
      },
      "outputs": [],
      "source": [
        "transform = Transform(stocks_hist, test_size=.05, X_days=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BYiKA2g7V-xu"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, scaler = transform.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1gUM7eROnBeO"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "class Model():\n",
        "  def __init__(self, X_train, y_train, X_test, y_test, scaler):\n",
        "    self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test\n",
        "    self.scaler = scaler\n",
        "\n",
        "  def fit(self):\n",
        "    self.lstm={}\n",
        "    for ticker in self.X_train.keys():\n",
        "      self.lstm[ticker] = Sequential()\n",
        "      self.lstm[ticker].add(LSTM(128, return_sequences=True, input_shape= (self.X_train[ticker].shape[1], 1)))\n",
        "      self.lstm[ticker].add(LSTM(64, return_sequences=False))\n",
        "      self.lstm[ticker].add(Dense(25))\n",
        "      self.lstm[ticker].add(Dense(1))\n",
        "\n",
        "      # Compile the model\n",
        "      self.lstm[ticker].compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "      # Train the model\n",
        "      self.lstm[ticker].fit(self.X_train[ticker], self.y_train[ticker], batch_size=1, epochs=1)\n",
        "\n",
        "  def _risk(self):\n",
        "    self.risk={}\n",
        "    for ticker in self.X_test.keys():\n",
        "      self.risk[ticker]=np.std((np.diff(self.X_test[ticker][:,:,0])/self.X_test[ticker][:,0:-1,0]), axis=1).mean()\n",
        "\n",
        "  def predict(self):\n",
        "    self.predictions={}\n",
        "    self.label={}\n",
        "\n",
        "    for ticker in self.X_test.keys():\n",
        "      self.predictions[ticker] = self.lstm[ticker].predict(self.X_test[ticker])\n",
        "      self.predictions[ticker] = self.scaler[ticker].inverse_transform(self.predictions[ticker])\n",
        "\n",
        "    for ticker in self.y_test.keys():\n",
        "      self.label[ticker] = self.scaler[ticker].inverse_transform(self.y_test[ticker].reshape(-1, 1))\n",
        "\n",
        "    self._risk()\n",
        "\n",
        "    return self.label, self.predictions, self.risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "d948XkfCpckt"
      },
      "outputs": [],
      "source": [
        "lstm = Model(X_train, y_train, X_test, y_test, scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS_ZgFCVpyNa",
        "outputId": "fa18b78e-302f-444b-ba2f-652312998c1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2808/2808 [==============================] - 176s 61ms/step - loss: 0.0011\n",
            "2808/2808 [==============================] - 172s 60ms/step - loss: 0.0015\n",
            "2808/2808 [==============================] - 179s 62ms/step - loss: 0.0012\n",
            "2808/2808 [==============================] - 176s 61ms/step - loss: 0.0013\n"
          ]
        }
      ],
      "source": [
        "lstm.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgXVpbXcp0wL",
        "outputId": "f04b6751-d978-4eb8-e173-ff6ab3f171c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d4dca231000> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 38ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d4dca84ef80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3/3 [==============================] - 1s 39ms/step\n",
            "3/3 [==============================] - 1s 36ms/step\n",
            "3/3 [==============================] - 1s 37ms/step\n"
          ]
        }
      ],
      "source": [
        " label, predictions, risk = lstm.predict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "bKDMzw6xv3KO"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2={}\n",
        "\n",
        "for ticker in predictions.keys():\n",
        "  r2[ticker] = r2_score(label[ticker], predictions[ticker])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UyeqmuJJmeM",
        "outputId": "a5e6f472-82ef-46dc-fd2c-362979e85ec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n",
            "AAPL\n",
            "Today: 173\n",
            "Tomorrow: 179\n",
            "Price change: 3.62%\n",
            "Risk: 0.0121\n",
            "R2: -0.0142\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "GOOG\n",
            "Today: 142\n",
            "Tomorrow: 148\n",
            "Price change: 3.99%\n",
            "Risk: 0.0193\n",
            "R2: -0.5777\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "MSFT\n",
            "Today: 416\n",
            "Tomorrow: 371\n",
            "Price change: -10.8%\n",
            "Risk: 0.0129\n",
            "R2: -4.1765\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "AMZN\n",
            "Today: 174\n",
            "Tomorrow: 187\n",
            "Price change: 7.3%\n",
            "Risk: 0.0193\n",
            "R2: 0.4017\n"
          ]
        }
      ],
      "source": [
        "for ticker in X_test.keys():\n",
        "  data_s = scaler[ticker].transform(stocks_hist[ticker].tail(60).values.reshape(-1, 1))\n",
        "  pred_s = lstm.lstm[ticker].predict(data_s.reshape(1,-1, 1))\n",
        "  pred = scaler[ticker].inverse_transform(pred_s.reshape(-1, 1))\n",
        "  print(ticker)\n",
        "  print(\"Today: \" + str(round(stocks_hist[ticker].iloc[-1])))\n",
        "  print(\"Tomorrow: \" + str(round(pred[0][0])))\n",
        "  print(\"Price change: \" + str(round(((pred[0][0]-stocks_hist[ticker].iloc[-1])/stocks_hist[ticker].iloc[-1])*100, 2)) + \"%\")\n",
        "  print(\"Risk: \" + str(round(risk[ticker], 4)))\n",
        "  print(\"R2: \" + str(round(r2[ticker], 4)))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
